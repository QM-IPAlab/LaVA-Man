{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d98bb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/acw694/.conda/envs/mae-cliport/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data/home/acw694/.conda/envs/mae-cliport/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def append_or_create_hdf5(hdf_file, dataset_name, data, dtype=None):\n",
    "    \"\"\"\n",
    "    Append data to an existing HDF5 dataset or create a new dataset if it doesn't exist.\n",
    "\n",
    "    Args:\n",
    "        hdf_file (h5py.File): The open HDF5 file object.\n",
    "        dataset_name (str): The name of the dataset to append to or create.\n",
    "        data (np.ndarray or list of str): The data to store. \n",
    "            - For images: Should be a numpy array with dtype uint8 and shape (H, W, C) or (B, H, W, C).\n",
    "            - For variable-length strings: Provide as a list of strings.\n",
    "        dtype (h5py.Datatype, optional): The datatype for variable-length data like strings.\n",
    "\n",
    "    Returns:\n",
    "        int: The new total number of items in the dataset after appending.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if data is image data or variable-length string data\n",
    "    if isinstance(data, np.ndarray):\n",
    "        # Assert image data type and shape\n",
    "        assert data.dtype == np.uint8, \"Input data must be of type uint8 (0-255 pixel values).\"\n",
    "        \n",
    "        if data.ndim == 3:\n",
    "            # Single image: (H, W, C) → Convert to batch (1, H, W, C)\n",
    "            assert data.shape[2] in [1, 3], \"Image must have 1 (grayscale) or 3 (RGB) channels.\"\n",
    "            data = np.expand_dims(data, axis=0)\n",
    "        \n",
    "        elif data.ndim == 4:\n",
    "            # Batch of images: (B, H, W, C)\n",
    "            assert data.shape[3] in [1, 3], \"Images must have 1 (grayscale) or 3 (RGB) channels.\"\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Input data must have shape (H, W, C) or (B, H, W, C).\")\n",
    "\n",
    "        # Create or append to the dataset\n",
    "        if dataset_name in hdf_file:\n",
    "            dset = hdf_file[dataset_name]\n",
    "            dset.resize(dset.shape[0] + data.shape[0], axis=0)\n",
    "            dset[-data.shape[0]:] = data\n",
    "        else:\n",
    "            maxshape = (None,) + data.shape[1:]  # Allow unlimited growth in the batch dimension\n",
    "            chunks = (1,) + data.shape[1:]       # Store data in chunks for better performance\n",
    "            hdf_file.create_dataset(dataset_name, data=data, maxshape=maxshape, chunks=chunks)\n",
    "\n",
    "        return hdf_file[dataset_name].shape[0]\n",
    "\n",
    "    elif isinstance(data, list) and all(isinstance(item, str) for item in data):\n",
    "        # Handle variable-length string data\n",
    "        dt = h5py.special_dtype(vlen=str) if dtype is None else dtype\n",
    "\n",
    "        if dataset_name in hdf_file:\n",
    "            dset = hdf_file[dataset_name]\n",
    "            dset.resize(dset.shape[0] + len(data), axis=0)\n",
    "            dset[-len(data):] = data\n",
    "        else:\n",
    "            maxshape = (None,)\n",
    "            chunks = (1,)  # Suitable for variable-length data\n",
    "            hdf_file.create_dataset(dataset_name, data=data, maxshape=maxshape, chunks=chunks, dtype=dt)\n",
    "\n",
    "        return hdf_file[dataset_name].shape[0]\n",
    "\n",
    "    else:\n",
    "        raise TypeError(\"Unsupported data type. Expected numpy array for images or list of strings for text.\")\n",
    "\n",
    "\n",
    "\n",
    "# 如果需要使用标准的变换\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.Resize(256),          # 先调整大小，确保最小边大于224\n",
    "    transforms.CenterCrop(224),      # 中心裁剪到224x224\n",
    "    transforms.ToTensor(),           # 转换为Tensor\n",
    "])\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to('cuda' if torch.cuda.is_available() else 'cpu') # type: ignore\n",
    "\n",
    "\n",
    "class ImagePairDataset(Dataset):\n",
    "    def __init__(self, root_dir, json_file, transform=None, frame_offset=30, num_images=10):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "\n",
    "        Args:\n",
    "            root_dir (str): 数据集根目录\n",
    "            json_file (str): 选择的序列JSON文件\n",
    "            transform (callable, optional): 应用于图像的变换\n",
    "            frame_offset (int): 生成图像对时的帧偏移量\n",
    "            num_images (int): 每个子文件夹随机选择的图片数量\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.frame_offset = frame_offset\n",
    "        self.num_images = num_images\n",
    "\n",
    "        # 加载JSON文件\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "        # 准备图像对列表\n",
    "        self.image_pairs = self._prepare_image_pairs()\n",
    "\n",
    "    def _prepare_image_pairs(self):\n",
    "        image_pairs = []\n",
    "\n",
    "        for category, folders in self.data.items():  # return key-value\n",
    "            for folder, frames in folders.items():\n",
    "                # 如果帧数量少于需要的随机数量，选择全部，否则随机选择指定数量\n",
    "                if len(frames) < self.num_images:\n",
    "                    selected_frames = frames\n",
    "                else:\n",
    "                    selected_frames = random.sample(frames, self.num_images)\n",
    "\n",
    "                # 为每个选择的帧生成图像对\n",
    "                for frame in selected_frames:\n",
    "                    pair_frame = self._get_pair_frame(frame, frames)\n",
    "                    if pair_frame is not None:\n",
    "                        img1_path = os.path.join(self.root_dir, category, folder, 'images', f'frame{frame:06d}.jpg')\n",
    "                        img2_path = os.path.join(self.root_dir, category, folder, 'images', f'frame{pair_frame:06d}.jpg')\n",
    "                        image_pairs.append((img1_path, img2_path))\n",
    "\n",
    "        return image_pairs\n",
    "\n",
    "    def _get_pair_frame(self, frame, frames):\n",
    "        \"\"\"根据给定帧生成±30范围内的帧 确保不越界。\"\"\"\n",
    "        valid_frames = [f for f in frames if abs(f - frame) <= self.frame_offset and f != frame]\n",
    "        if valid_frames:\n",
    "            return random.choice(valid_frames)\n",
    "        return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1_path, img2_path = self.image_pairs[idx]\n",
    "\n",
    "        img1_pil = Image.open(img1_path).convert('RGB')\n",
    "        img2_pil = Image.open(img2_path).convert('RGB')\n",
    "\n",
    "        img1_np = np.array(img1_pil, dtype=np.uint8)\n",
    "        img2_np = np.array(img2_pil, dtype=np.uint8)\n",
    "\n",
    "        return img1_np, img2_np\n",
    "\n",
    "\n",
    "def generate_caption(image):\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs) # type: ignore\n",
    "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b04c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImagePairDataset(\n",
    "        root_dir='scratch/co3d',  # 数据集根目录\n",
    "        json_file='scratch/co3d/selected_seqs_train.json',  # JSON文件路径\n",
    "        transform=default_transform  # 图像转换\n",
    "    )\n",
    "\n",
    "# 创建 HDF5 文件并保存数据\n",
    "with h5py.File('image_pairs_with_captions.hdf5', 'w') as hdf:\n",
    "    captions = []\n",
    "\n",
    "    for idx, (img1_np, img2_np) in enumerate(dataset): # type: ignore\n",
    "        # 生成文字描述\n",
    "        caption = generate_caption(img1_np)\n",
    "        captions.append(caption.encode('ascii'))\n",
    "\n",
    "        append_or_create_hdf5(hdf, 'image1', img1_np)\n",
    "        append_or_create_hdf5(hdf, 'image2', img2_np)\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(f'Saved {idx + 1} image pairs with captions')\n",
    "\n",
    "        if idx % 100 == 0: break\n",
    "\n",
    "    # Save all captions at once\n",
    "    append_or_create_hdf5(hdf, 'captions', captions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mae-cliport",
   "language": "python",
   "name": "mae-cliport"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
