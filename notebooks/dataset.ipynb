{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a62ae2",
   "metadata": {},
   "source": [
    "# Dataset Visualizer\n",
    "\n",
    "This notebook visualizes a pre-generated dataset of expert demonstrations collected with demos.py\n",
    "\n",
    "### Setup\n",
    "\n",
    "- Set the root folder environment variable with `export CLIPORT_ROOT=<cliport_root>`\n",
    "- Run `python cliport/demos.py n=10 mode=train task=stack-block-pyramid-seq-seen-colors` to generate a dataset for `train`, `val`, or `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c529fa2",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import hydra\n",
    "\n",
    "from cliport.dataset import RavensDataset\n",
    "from cliport.utils import utils\n",
    "from cliport import tasks\n",
    "from cliport.environments.environment import Environment\n",
    "\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6a78065c",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa08d59",
   "metadata": {},
   "source": [
    "### task settings\n",
    "mode = 'train'\n",
    "augment = True\n",
    "\n",
    "### Uncomment the task you want to generate ###\n",
    "# task = 'align-rope'\n",
    "# task = 'assembling-kits-seq-seen-colors'\n",
    "# task = 'assembling-kits-seq-unseen-colors'\n",
    "# task = 'assembling-kits-seq-full'\n",
    "# task = 'packing-shapes'\n",
    "# task = 'packing-boxes-pairs-seen-colors'\n",
    "# task = 'packing-boxes-pairs-unseen-colors'\n",
    "# task = 'packing-boxes-pairs-full'\n",
    "# task = 'packing-seen-google-objects-seq'\n",
    "# task = 'packing-unseen-google-objects-seq'\n",
    "# task = 'packing-seen-google-objects-group'\n",
    "# task = 'packing-unseen-google-objects-group'\n",
    "# task = 'put-block-in-bowl-seen-colors'\n",
    "# task = 'put-block-in-bowl-unseen-colors'\n",
    "# task = 'put-block-in-bowl-full'\n",
    "task = 'stack-block-pyramid-seq-seen-colors'\n",
    "# task = 'stack-block-pyramid-seq-unseen-colors'\n",
    "# task = 'stack-block-pyramid-seq-full'\n",
    "# task = 'separating-piles-seen-colors'\n",
    "# task = 'separating-piles-unseen-colors'\n",
    "# task = 'separating-piles-full'\n",
    "# task = 'towers-of-hanoi-seq-seen-colors'\n",
    "# task = 'towers-of-hanoi-seq-unseen-colors'\n",
    "# task = 'towers-of-hanoi-seq-full'\n",
    "\n",
    "### visualization settings\n",
    "max_episodes = 1\n",
    "max_steps = 100"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "62941225",
   "metadata": {},
   "source": [
    "### Load configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73676ada",
   "metadata": {},
   "source": [
    "# Load configs\n",
    "root_dir = os.environ['CLIPORT_ROOT']\n",
    "config_file = 'train.yaml' \n",
    "cfg = utils.load_hydra_config(os.path.join(root_dir, f'cliport/cfg/{config_file}'))\n",
    "\n",
    "# Override defaults\n",
    "cfg['task'] = task\n",
    "cfg['mode'] = mode\n",
    "\n",
    "data_dir = os.path.join(root_dir, 'data')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a48693b6",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fea08d",
   "metadata": {},
   "source": [
    "task = tasks.names[cfg['task']]()\n",
    "task.mode = mode\n",
    "\n",
    "ds = RavensDataset(os.path.join(data_dir, f'{cfg[\"task\"]}-{cfg[\"mode\"]}'), cfg, augment=augment)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "caec9950",
   "metadata": {},
   "source": [
    "### Iterate through dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b25625",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "color_sums = []\n",
    "depth_sums = []\n",
    "\n",
    "total_images = 0\n",
    "\n",
    "for i in range(0, min(max_episodes, ds.n_episodes)):\n",
    "    print(f'\\n\\nEpisode: {i + 1}/{ds.n_episodes}')\n",
    "    episode, seed = ds.load(i)\n",
    "    \n",
    "    total_images += len(episode)-1\n",
    "    \n",
    "    total_reward = 0\n",
    "    for step in range(min(max_steps, len(episode))):\n",
    "        print(f\"\\nStep: {step+1}/{len(episode)}\")\n",
    "        obs, act, reward, info = episode[step]\n",
    "        \n",
    "        total_reward += reward\n",
    "        batch = ds[i]\n",
    "        \n",
    "        num_images = len(obs['color'])\n",
    "        fig, axs = plt.subplots(2, num_images+1, figsize=(15, 6))\n",
    "        for n in range(num_images):\n",
    "            axs[1, n].imshow(obs['color'][n])\n",
    "            axs[1, n].set_title(f'Raw RGB {n+1}')\n",
    "            \n",
    "            axs[0, n].imshow(obs['depth'][n])\n",
    "            axs[0, n].set_title(f'Raw Depth {n+1}')\n",
    "            \n",
    "        color_sums.append(np.mean(obs['color'][0], axis=(0,1)) / 255.0)\n",
    "        depth_sums.append(np.mean(obs['depth'][0], axis=(0,1)))\n",
    "        \n",
    "        cam_config = None\n",
    "        if b'camera_info' in info:\n",
    "            cam_config = ds.get_cam_config(info[b'camera_info'])\n",
    "        \n",
    "        img_depth = ds.get_image(obs, cam_config=cam_config)\n",
    "        img_tensor = torch.from_numpy(img_depth)\n",
    "        img = np.uint8(img_tensor.detach().cpu().numpy())\n",
    "        img = img.transpose(1,0,2)\n",
    "        \n",
    "        if step < len(episode)-1 and episode[step]:\n",
    "            batch = ds.process_sample(episode[step], augment=augment)\n",
    "        else:\n",
    "            batch = ds.process_goal(episode[step], perturb_params=None)\n",
    "        \n",
    "        img_sample = batch['img']\n",
    "        img_sample = torch.from_numpy(img_sample)\n",
    "        color = np.uint8(img_sample.detach().cpu().numpy())[:,:,:3]\n",
    "        color = color.transpose(1,0,2)\n",
    "        depth = np.array(img_sample.detach().cpu().numpy())[:,:,3]\n",
    "        depth = depth.transpose(1,0)\n",
    "        \n",
    "        axs[0, num_images].imshow(depth)\n",
    "        axs[0, num_images].set_title('Depth')\n",
    "        \n",
    "        axs[1,num_images].imshow(color)\n",
    "        axs[1,num_images].set_title('RGB + Oracle Pick & Place')\n",
    "        \n",
    "        if act and step < len(episode)-1:\n",
    "            p0 = batch['p0']\n",
    "            p1 = batch['p1']\n",
    "            p0_theta = batch['p0_theta']\n",
    "            p1_theta = batch['p1_theta'] + p0_theta\n",
    "            \n",
    "            pick = p0\n",
    "            place = p1\n",
    "                \n",
    "            line_len = 30\n",
    "            pick0 = (pick[0] + line_len/2.0 * np.sin(p0_theta), pick[1] + line_len/2.0 * np.cos(p0_theta))\n",
    "            pick1  = (pick[0] - line_len/2.0 * np.sin(p0_theta), pick[1] - line_len/2.0 * np.cos(p0_theta))\n",
    "            axs[1,num_images].plot((pick1[0], pick0[0]), (pick1[1], pick0[1]), color='r', linewidth=2)\n",
    "            \n",
    "            place0 = (place[0] + line_len/2.0 * np.sin(p1_theta), place[1] + line_len/2.0 * np.cos(p1_theta))\n",
    "            place1  = (place[0] - line_len/2.0 * np.sin(p1_theta), place[1] - line_len/2.0 * np.cos(p1_theta))\n",
    "            axs[1,num_images].plot((place1[0], place0[0]), (place1[1], place0[1]), color='g', linewidth=2)\n",
    "            \n",
    "            c_pick = plt.Circle(pick, 3, color='r', fill=False)\n",
    "            c_place = plt.Circle(place, 3, color='g', fill=False)\n",
    "\n",
    "            axs[1,num_images].add_patch(c_pick)\n",
    "            axs[1,num_images].add_patch(c_place)\n",
    "            \n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Language Goal: {batch['lang_goal']}\")\n",
    "        print(f\"Step Reward: {reward}\")\n",
    "        print(f\"Total Reward: {total_reward}\")\n",
    "\n",
    "    print(f\"Done, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"\\n\\nDataset Statistics: \")\n",
    "print(f\"Color Mean: {np.mean(color_sums, axis=0)}, Std: {np.std(color_sums, axis=0)}\")\n",
    "print(f\"Depth Mean: {np.mean(depth_sums, axis=0)}, Std: {np.std(depth_sums, axis=0)}\")\n",
    "print(f\"Total Image-Action Pairs: {total_images}\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
