# Training
# Ours parameter
pretrain_path: /jmain02/home/J2AD007/txk47/cxz00-txk47/cliport/checkpoints/mae_pretrain_vit_base.pth
mae_model: mae_robot_lang # pre-train mae model wrapped in downstream model
cliport_checkpoint: /jmain02/home/J2AD007/txk47/cxz00-txk47/cliport/checkpoints/steps=400000-val_loss=0.00013902.ckpt
text_model: openai/clip-vit-base-patch32

defaults:
  - config

hydra:
  run:
    dir: ${train.train_dir}

dataset:
  type: 'single' # 'single' or 'multi'
  images: True
  cache: True # load episodes to memory instead of reading from disk
  augment:
    theta_sigma: 60 # rotation sigma in degrees; N(mu = 0, sigma = theta_sigma).
  mode: 'train' # 'train' or 'val' or 'test'
  aug: True

train:
  # folders
  exp_folder: exps
  train_dir: ${root_dir}/${train.exp_folder}/${train.task}-${train.agent}-n${train.n_demos}-train
  data_dir: ${root_dir}/data

  # task configs
  task: packing-boxes-pairs-seen-colors
  agent: two_stream_full_clip_lingunet_lat_transporter
  n_demos: 1000
  n_steps: 201000 # use 601000 for multi-task models

  # hyper params
  n_rotations: 36
  batchnorm: False # important: False because batch_size=1
  lr: 1e-4
  lr_scheduler: False
  batch_size: 1
  precision: 32
  sep_mode: False
  lr_min: 0.0
  warmup_epochs: 0

  attn_stream_fusion_type: 'add'
  trans_stream_fusion_type: 'conv'
  lang_fusion_type: 'mult'

  # script configs
  gpu: [0] # -1 for all
  log: False # log metrics and stats to wandb
  n_val: 100
  val_repeats: 1
  save_steps: [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 55000, 60000, 80000, 120000, 160000, 200000, 300000, 400000, 500000, 600000, 800000, 1000000, 1200000]
  load_from_last_ckpt: True
  load_pretrained_ckpt: False
  accumulate_grad_batches: 1
  linear_probe: False

wandb:
  run_name: 'cliport0'
  logger:
    entity: cliport
    project: cliport
    tags: []
    group: train
    offline: False
  saver:
    upload: False
    monitor: 'val_loss'